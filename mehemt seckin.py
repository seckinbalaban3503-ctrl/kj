import cv2
import time
import numpy as np
from ultralytics import YOLO
from collections import defaultdict
import threading
from queue import Queue

VIDEO_SOURCE = "http://10.49.117.187:4747/video"

# Ekran dÃ¶ndÃ¼rme ayarÄ±: 0=normal, 1=90Â°, 2=180Â°, 3=270Â°
rotation_mode = 1
fullscreen = False

# HÄ±z dÃ¶nÃ¼ÅŸÃ¼m faktÃ¶rÃ¼: piksel/saniye -> km/saat
# Bu deÄŸer kameranÄ±n yÃ¼ksekliÄŸi ve aÃ§Ä±sÄ±na gÃ¶re kalibre edilmeli
# VarsayÄ±lan: 1 piksel = 0.01 metre (yaklaÅŸÄ±k deÄŸer, gerÃ§ek kullanÄ±mda kalibre edilmeli)
PIXEL_TO_METER = 0.01  # Metre/piksel
METER_TO_KMH = 3.6     # m/s -> km/h dÃ¶nÃ¼ÅŸÃ¼m faktÃ¶rÃ¼

model = YOLO("yolov8n-seg.pt")
cap = cv2.VideoCapture(VIDEO_SOURCE)

# AÄŸ gecikmesini azaltmak iÃ§in agresif optimizasyonlar
cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Buffer'Ä± kÃ¼Ã§Ã¼lt (eski frame'leri atla)
cap.set(cv2.CAP_PROP_FPS, 30)  # FPS limiti
# Ã‡Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ dÃ¼ÅŸÃ¼r - performans iÃ§in kritik
# Not: Kamera 640x480 gÃ¶nderir, 90Â° dÃ¶ndÃ¼rme sonrasÄ± 480x640 olur
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

time.sleep(2)
if not cap.isOpened():
    print("âŒ Kamera aÃ§Ä±lamadÄ±")
    exit()

print("âœ… Kamera aÃ§Ä±ldÄ±")
print("ğŸ“± Klavye Kontrolleri:")
print("   'r' tuÅŸu: EkranÄ± dÃ¶ndÃ¼r (0Â° â†’ 90Â° â†’ 180Â° â†’ 270Â° â†’ 0Â°)")
print("   'f' tuÅŸu: Full ekran aÃ§/kapat")
print("   'q' tuÅŸu: Ã‡Ä±kÄ±ÅŸ")
print("\nğŸ’¡ AÄŸ Gecikmesi Ä°puÃ§larÄ±:")
print("   - WiFi yerine kablolu baÄŸlantÄ± kullanÄ±n")
print("   - Telefon ve bilgisayar aynÄ± WiFi aÄŸÄ±nda olmalÄ±")
print("   - DroidCam'de dÃ¼ÅŸÃ¼k kalite modunu deneyin")
print("   - Router'a yakÄ±n olun")

# Pencereyi oluÅŸtur
cv2.namedWindow("INSAN HIZ TESPITI", cv2.WINDOW_NORMAL)

# Threading iÃ§in frame queue
frame_queue = Queue(maxsize=2)  # Sadece en son 2 frame'i tut
latest_frame = None
frame_lock = threading.Lock()

# Her insan iÃ§in Ã¶nceki pozisyon ve zaman bilgilerini sakla
person_tracks = defaultdict(lambda: {'prev_center': None, 'prev_time': None, 'id': None})
next_id = 0

# FPS hesaplama iÃ§in
fps_start_time = time.time()
fps_frame_count = 0
fps = 0

# Frame okuma thread fonksiyonu
def read_frames():
    """Frame'leri ayrÄ± thread'de oku"""
    global latest_frame
    while True:
        ret, frame = cap.read()
        if ret:
            with frame_lock:
                latest_frame = frame.copy()
        else:
            time.sleep(0.01)  # Hata durumunda kÄ±sa bekleme

# Frame okuma thread'ini baÅŸlat
frame_thread = threading.Thread(target=read_frames, daemon=True)
frame_thread.start()
time.sleep(1)  # Thread'in baÅŸlamasÄ± iÃ§in bekle

def calculate_iou(mask1, mask2):
    """Ä°ki mask arasÄ±ndaki IoU (Intersection over Union) deÄŸerini hesapla - optimize edilmiÅŸ"""
    # Daha hÄ±zlÄ± hesaplama iÃ§in Ã¶rnekleme
    h, w = mask1.shape
    step = max(1, min(h, w) // 50)  # Her 50 pikselde bir Ã¶rnekle
    
    mask1_sampled = mask1[::step, ::step]
    mask2_sampled = mask2[::step, ::step]
    
    intersection = np.logical_and(mask1_sampled, mask2_sampled).sum()
    union = np.logical_or(mask1_sampled, mask2_sampled).sum()
    if union == 0:
        return 0
    return intersection / union

def merge_close_detections(detections, iou_threshold=0.4, distance_threshold=60):
    """Birbirine Ã§ok yakÄ±n algÄ±lamalarÄ± birleÅŸtir"""
    if len(detections) == 0:
        return []
    
    merged = []
    used = [False] * len(detections)
    
    for i, det1 in enumerate(detections):
        if used[i]:
            continue
        
        # Bu algÄ±lamayÄ± birleÅŸtirilmiÅŸ listeye ekle
        merged_det = det1.copy()
        used[i] = True
        
        # DiÄŸer algÄ±lamalarla karÅŸÄ±laÅŸtÄ±r
        for j, det2 in enumerate(detections):
            if i == j or used[j]:
                continue
            
            # Merkez mesafesi kontrolÃ¼
            cx1, cy1 = det1['center']
            cx2, cy2 = det2['center']
            dist = np.sqrt((cx1 - cx2)**2 + (cy1 - cy2)**2)
            
            # IoU kontrolÃ¼
            iou = calculate_iou(det1['mask'], det2['mask'])
            
            # EÄŸer Ã§ok yakÄ±nsa birleÅŸtir
            if dist < distance_threshold or iou > iou_threshold:
                # Daha bÃ¼yÃ¼k mask'Ä± kullan (daha gÃ¼venilir)
                if det2['mask'].sum() > merged_det['mask'].sum():
                    merged_det = det2.copy()
                used[j] = True
        
        merged.append(merged_det)
    
    return merged

while True:
    # Threading'den en son frame'i al
    with frame_lock:
        if latest_frame is None:
            time.sleep(0.01)
            continue
        frame = latest_frame.copy()
    
    # EkranÄ± dÃ¶ndÃ¼r
    if rotation_mode == 1:
        frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
    elif rotation_mode == 2:
        frame = cv2.rotate(frame, cv2.ROTATE_180)
    elif rotation_mode == 3:
        frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)

    h, w = frame.shape[:2]
    current_time = time.time()
    
    # FPS hesaplama
    fps_frame_count += 1
    if current_time - fps_start_time >= 1.0:
        fps = fps_frame_count / (current_time - fps_start_time)
        fps_frame_count = 0
        fps_start_time = current_time

    # Sadece insanlarÄ± algÄ±la (class 0 = person)
    # 90Â° dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ gÃ¶rÃ¼ntÃ¼ iÃ§in optimize edilmiÅŸ: 480x640 boyutlarÄ±na uygun imgsz
    # DÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ gÃ¶rÃ¼ntÃ¼ 480x640 olduÄŸu iÃ§in 480 kullanÄ±yoruz
    results = model(frame, conf=0.4, classes=[0], imgsz=480, verbose=False, half=False)

    # TÃ¼m algÄ±lamalarÄ± topla
    all_detections = []
    
    for r in results:
        if r.masks is None:
            continue

        for i, mask_data in enumerate(r.masks.data):
            mask = mask_data.cpu().numpy()
            # Mask'Ä± frame boyutuna resize et
            if mask.shape != (h, w):
                mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)

            # Daha hÄ±zlÄ± merkez hesaplama - sadece Ã¶rnekleme yap
            ys, xs = np.where(mask > 0.5)
            if len(ys) < 10:  # Ã‡ok kÃ¼Ã§Ã¼k mask'larÄ± atla
                continue

            # Ã–rnekleme ile daha hÄ±zlÄ± hesaplama
            step = max(1, len(ys) // 100)  # Maksimum 100 nokta kullan
            cy = int(np.mean(ys[::step]))
            cx = int(np.mean(xs[::step]))
            
            all_detections.append({
                'center': (cx, cy),
                'mask': mask
            })

    # Ã‡ift algÄ±lamalarÄ± birleÅŸtir
    merged_detections = merge_close_detections(all_detections)
    
    # Her birleÅŸtirilmiÅŸ algÄ±lamayÄ± iÅŸle
    for det in merged_detections:
        cx, cy = det['center']
        
        # En yakÄ±n takip edilen kiÅŸiyi bul veya yeni ID ata
        min_dist = float('inf')
        matched_id = None
        
        for person_id, track_data in person_tracks.items():
            if track_data['prev_center'] is not None:
                prev_cx, prev_cy = track_data['prev_center']
                dist = np.sqrt((cx - prev_cx)**2 + (cy - prev_cy)**2)
                # 90Â° dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ gÃ¶rÃ¼ntÃ¼ iÃ§in optimize edilmiÅŸ mesafe eÅŸiÄŸi (480x640 boyutlarÄ±na gÃ¶re)
                if dist < min_dist and dist < 120:  # 120 piksel mesafe eÅŸiÄŸi (dikey gÃ¶rÃ¼ntÃ¼ iÃ§in optimize)
                    min_dist = dist
                    matched_id = person_id

        if matched_id is None:
            matched_id = next_id
            next_id += 1
            person_tracks[matched_id]['id'] = matched_id

        # HÄ±z hesapla
        track_data = person_tracks[matched_id]
        speed = 0.0
        
        if track_data['prev_center'] is not None and track_data['prev_time'] is not None:
            prev_cx, prev_cy = track_data['prev_center']
            dt = current_time - track_data['prev_time']
            
            if dt > 0:
                # Ã–klid mesafesi kullanarak hÄ±z hesapla (piksel/saniye)
                distance_px = np.sqrt((cx - prev_cx)**2 + (cy - prev_cy)**2)
                speed_px_per_s = distance_px / dt
                
                # Piksel/saniye -> metre/saniye -> km/saat
                speed_m_per_s = speed_px_per_s * PIXEL_TO_METER
                speed = speed_m_per_s * METER_TO_KMH  # km/h

        # GÃ¼ncelle
        person_tracks[matched_id]['prev_center'] = (cx, cy)
        person_tracks[matched_id]['prev_time'] = current_time

        # GÃ¶rselleÅŸtir
        cv2.circle(frame, (cx, cy), 8, (0, 255, 0), -1)
        cv2.circle(frame, (cx, cy), 12, (0, 255, 0), 2)
        
        # HÄ±z bilgisini gÃ¶ster (km/h)
        speed_text = f"ID:{matched_id} Hiz: {speed:.2f} km/h"
        cv2.putText(frame, speed_text, (cx - 70, cy - 20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # Uzun sÃ¼re gÃ¶rÃ¼nmeyen kiÅŸileri temizle (5 saniye)
    to_remove = []
    for person_id, track_data in person_tracks.items():
        if track_data['prev_time'] is not None:
            if current_time - track_data['prev_time'] > 5.0:
                to_remove.append(person_id)
    
    for person_id in to_remove:
        del person_tracks[person_id]

    # Frame baÅŸÄ±na bilgi gÃ¶ster
    info_text = f"Tespit Edilen Insan: {len(merged_detections)}"
    cv2.putText(frame, info_text, (10, 30),
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    # FPS gÃ¶ster
    fps_text = f"FPS: {fps:.1f}"
    cv2.putText(frame, fps_text, (10, 60),
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
    
    # DÃ¶ndÃ¼rme bilgisini gÃ¶ster
    rotation_texts = ["Normal", "90Â°", "180Â°", "270Â°"]
    cv2.putText(frame, f"Ekran: {rotation_texts[rotation_mode]}", (10, 90),
               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

    cv2.imshow("INSAN HIZ TESPITI", frame)
    
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break
    elif key == ord('r'):
        rotation_mode = (rotation_mode + 1) % 4
        print(f"ğŸ“± Ekran dÃ¶ndÃ¼rme: {rotation_texts[rotation_mode]}")
    elif key == ord('f'):
        fullscreen = not fullscreen
        if fullscreen:
            cv2.setWindowProperty("INSAN HIZ TESPITI", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
            print("ğŸ“º Full ekran: AÃ‡IK")
        else:
            cv2.setWindowProperty("INSAN HIZ TESPITI", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)
            print("ğŸ“º Full ekran: KAPALI")

cap.release()
cv2.destroyAllWindows()